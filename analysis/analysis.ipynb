{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# PATH = \"\"\n",
    "PATH = \"../../dtn7-lab/shared/scenarios/correctness/others/results-correctness_others-1681488012/\"\n",
    "\n",
    "# Load path\n",
    "# with open('.nbconfig', 'r') as file:\n",
    "#     arguments = json.load(file)\n",
    "#     PATH = arguments[\"path\"]\n",
    "\n",
    "print(f\"Report for {PATH}\")\n",
    "\n",
    "with open(PATH + \"start.txt\") as file:\n",
    "    simStart = int(file.readline().strip())\n",
    "with open(PATH + \"stop.txt\") as file:\n",
    "    simStop = int(file.readline().strip())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotResourceGraphs():\n",
    "    logfiles = []\n",
    "\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        for file in files:\n",
    "            if file in [\"pidstat-base.csv.log\", \"pidstat-robot.csv.log\"]:\n",
    "                logfiles.append(root + \"/\" + file)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        subplot_titles=(\"Base\", \"Robot\"),\n",
    "        specs=[[{\"secondary_y\": True}, {\"secondary_y\": True}]],\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Time [s]\")\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"RSS [kB]\",\n",
    "        secondary_y=False,\n",
    "        titlefont=dict(color=\"#ab63fa\"),\n",
    "        tickfont=dict(color=\"#ab63fa\"),\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"CPU Usage [%]\",\n",
    "        secondary_y=True,\n",
    "        titlefont=dict(color=\"#00cc96\"),\n",
    "        tickfont=dict(color=\"#00cc96\"),\n",
    "    )\n",
    "    fig.update_layout(title_text=\"Resource Usage\", showlegend=False)\n",
    "\n",
    "    for file in logfiles:\n",
    "        # Get node name\n",
    "        nodeName = re.search(r\"/pidstat-(\\w*)\", file).group(1)\n",
    "        column = 1 if (\"base\" in nodeName) else 2\n",
    "\n",
    "        # Get number of CPU Cores\n",
    "        with open(file.replace(\".csv\", \"\")) as f:\n",
    "            cpuCores = int(re.search(r\"\\((\\d*) CPU\\)\", f.readline()).group(1))\n",
    "\n",
    "        df = pd.read_csv(file, sep=\"\\s+\", usecols=[0, 7, 11, 12])\n",
    "        # substract start time\n",
    "        df = df.subtract([simStart, 0, 0, 0], axis=\"columns\")\n",
    "        # devide CPU usage by core count\n",
    "        df = df.divide([1, cpuCores, 1, 1], axis=\"columns\")\n",
    "\n",
    "        # plot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df[\"Time\"],\n",
    "                y=df[\"RSS\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"RSS\",\n",
    "                line=dict(color=\"#ab63fa\", width=2),\n",
    "            ),\n",
    "            secondary_y=False,\n",
    "            row=1,\n",
    "            col=column,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df[\"Time\"],\n",
    "                y=df[\"%CPU\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"CPU\",\n",
    "                line=dict(color=\"#00cc96\", width=2),\n",
    "            ),\n",
    "            secondary_y=True,\n",
    "            row=1,\n",
    "            col=column,\n",
    "        )\n",
    "\n",
    "        # Print mean values\n",
    "        stats = f\"Mean Values {nodeName}:\\nCPU: \\t{df.loc[:,'%CPU'].mean()} %\\nRSS: \\t{df.loc[:,'RSS'].mean()} kB\\n\"\n",
    "        print(stats)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plotResourceGraphs()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNetworkGraphs():\n",
    "    logfiles = {}\n",
    "\n",
    "    # find log files\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        for file in files:\n",
    "            m = re.match(r\"net-(.+).log\", file)\n",
    "            if m:\n",
    "                logfiles[m.group(1)] = root + \"/\" + file\n",
    "\n",
    "    # load data\n",
    "    dfs = []\n",
    "    for nodeName, file in logfiles.items():\n",
    "        df = pd.read_csv(\n",
    "            file,\n",
    "            sep=\";\",\n",
    "            usecols=[0, 1, 2, 3, 4],\n",
    "            names=\"timestamp;iface_name;bytes_out/s;bytes_in/s;bytes_total/s\".split(\n",
    "                \";\"\n",
    "            ),\n",
    "        )\n",
    "        df[\"node\"] = nodeName\n",
    "\n",
    "        # filter\n",
    "        df = df[df[\"iface_name\"] == \"eth0\"]\n",
    "        df = df[df[\"timestamp\"] > simStart]\n",
    "\n",
    "        # substract start time\n",
    "        df[\"timestamp\"] -= simStart\n",
    "        df[\"timestamp\"] = df[\"timestamp\"].astype(\"int\")\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.sort_values(by=[\"timestamp\", \"node\"])\n",
    "\n",
    "    # init figure\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        subplot_titles=(\"Traffic In\", \"Traffic Out\", \"Total Traffic\"),\n",
    "        vertical_spacing=0.1,\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Time [s]\")\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Traffic [B/s]\",\n",
    "    )\n",
    "    fig.update_layout(title_text=\"Network Usage\", height=900)\n",
    "\n",
    "    # plot data\n",
    "    colors = [\"#ab63fa\", \"#00cc96\", \"#ffa15a\"]\n",
    "    colorCnt = 0\n",
    "    for nodeName in df.node.unique():\n",
    "        nodeDf = df[df.node == nodeName]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=nodeDf[\"timestamp\"],\n",
    "                y=nodeDf[\"bytes_in/s\"],\n",
    "                mode=\"lines\",\n",
    "                name=nodeName,\n",
    "                line=dict(color=colors[colorCnt]),\n",
    "                legendgroup=colorCnt,\n",
    "                showlegend=True,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=nodeDf[\"timestamp\"],\n",
    "                y=nodeDf[\"bytes_out/s\"],\n",
    "                mode=\"lines\",\n",
    "                name=nodeName,\n",
    "                line=dict(color=colors[colorCnt]),\n",
    "                legendgroup=colorCnt,\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=nodeDf[\"timestamp\"],\n",
    "                y=nodeDf[\"bytes_total/s\"],\n",
    "                mode=\"lines\",\n",
    "                name=nodeName,\n",
    "                line=dict(color=colors[colorCnt]),\n",
    "                legendgroup=colorCnt,\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=3,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        colorCnt += 1\n",
    "\n",
    "    # plot means\n",
    "    meanIn = df[\"bytes_in/s\"].describe().T[\"mean\"]\n",
    "    meanOut = df[\"bytes_out/s\"].describe().T[\"mean\"]\n",
    "    meanTotal = df[\"bytes_total/s\"].describe().T[\"mean\"]\n",
    "\n",
    "    fig.add_hline(\n",
    "        meanIn,\n",
    "        line=dict(color=\"red\", dash=\"dash\", width=1),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_hline(\n",
    "        meanOut,\n",
    "        line=dict(color=\"red\", dash=\"dash\", width=1),\n",
    "        row=2,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_hline(\n",
    "        meanTotal,\n",
    "        line=dict(color=\"red\", dash=\"dash\", width=1),\n",
    "        row=3,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    print(\"(Combined Nodes) Mean Network usage:\")\n",
    "    print(\n",
    "        f\"In: \\t{meanIn:.2f} B/s\\nOut: \\t{meanOut:.2f} B/s\\nTotal: \\t{meanTotal:.2f} B/s\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nTotal Traffic:\")\n",
    "    for nodeName in df.node.unique():\n",
    "        nodeDf = df[df.node == nodeName]\n",
    "        print(\n",
    "            f\"{nodeName} \\tIn: {str(sum(nodeDf['bytes_in/s'])/1000) + ' kB':<15} Out: {sum(nodeDf['bytes_out/s'])/1000} kB\"\n",
    "        )\n",
    "\n",
    "\n",
    "plotNetworkGraphs()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing dtnd stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtndStats = {\"base\": {}, \"robot\": {}, \"combined\": {}}\n",
    "\n",
    "\n",
    "def loadDtndStats():\n",
    "    global dtnStats\n",
    "\n",
    "    # init\n",
    "    for node in dtndStats:\n",
    "        dtndStats[node][\"sentBundles\"] = {}\n",
    "        dtndStats[node][\"receivedBundles\"] = {}\n",
    "\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        for file in files:\n",
    "            if file != \"dtnd.log\":\n",
    "                continue\n",
    "            nodeName = re.search(r\"\\/(\\w*)$\", root).group(1)\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.read()\n",
    "\n",
    "            if nodeName in [\"base\", \"robot\"]:\n",
    "\n",
    "                dtndStats[nodeName][\"created\"] = len(re.findall(r\"Transmission of bundle requested\", content))\n",
    "                dtndStats[nodeName][\"transferred\"] = len(re.findall(r\"Sending bundle succeeded\", content))\n",
    "                dtndStats[nodeName][\"relayed\"] = len(re.findall(r\"Received new bundle\", content))\n",
    "                dtndStats[nodeName][\"aborted\"] = len(re.findall(r\"Sending bundle .+ failed\", content))\n",
    "                dtndStats[nodeName][\"dropped\"] = len(re.findall(r\"Dropping bundle\", content))\n",
    "                dtndStats[nodeName][\"removed\"] = len(re.findall(r\"Removing bundle\", content)) - dtndStats[nodeName][\"dropped\"]\n",
    "                dtndStats[nodeName][\"refused\"] = len(re.findall(r\"refusing bundle\", content))\n",
    "                dtndStats[nodeName][\"delivered\"] = len(re.findall(r\"Received bundle for local delivery\", content))\n",
    "\n",
    "                tmp = re.findall(r\"(\\d{4}-\\d{2}-\\d{2}T.+Z).*Received bundle for local delivery.+\\/\\/(.+)\", content)\n",
    "                for time, bid in tmp:\n",
    "                    dtndStats[nodeName][\"receivedBundles\"][bid] = datetime.fromisoformat(time).timestamp()\n",
    "                tmp = re.findall(r\"(\\d{4}-\\d{2}-\\d{2}T.+Z).*Transmission of bundle requested.+\\/\\/(.+)\", content)\n",
    "                for time, bid in tmp:\n",
    "                    dtndStats[nodeName][\"sentBundles\"][bid] = datetime.fromisoformat(time).timestamp()\n",
    "\n",
    "            try:\n",
    "                dtndStats[\"combined\"][\"transferred\"] = dtndStats[\"combined\"][\"transferred\"] + len(re.findall(r\"Sending bundle succeeded\", content))\n",
    "            except (KeyError):\n",
    "                dtndStats[\"combined\"][\"transferred\"] = len(re.findall(r\"Sending bundle succeeded\", content))\n",
    "\n",
    "loadDtndStats()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTN Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtnLatency():\n",
    "    global dtndStats\n",
    "\n",
    "    sentBundles = {\n",
    "        **dtndStats[\"base\"][\"sentBundles\"],\n",
    "        **dtndStats[\"robot\"][\"sentBundles\"],\n",
    "    }\n",
    "    receivedBundles = {\n",
    "        **dtndStats[\"base\"][\"receivedBundles\"],\n",
    "        **dtndStats[\"robot\"][\"receivedBundles\"],\n",
    "    }\n",
    "\n",
    "    # Calculate latency\n",
    "    latencyMap = defaultdict(list)\n",
    "\n",
    "    # To plot over time, latency values of bundles received in one second are combined\n",
    "    for bid, time in receivedBundles.items():\n",
    "        sTime = sentBundles[bid]\n",
    "        latency = time - sTime\n",
    "        latencyMap[int(time) + 1].append(latency)\n",
    "    latencyOverTime = {}\n",
    "    for time, val in latencyMap.items():\n",
    "        latencyOverTime[time - simStart] = sum(val) / len(val)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.update_xaxes(title_text=\"Time [s]\", range=[0, simStop - simStart])\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"DTN Latency [s]\",\n",
    "        titlefont=dict(color=\"#ab63fa\"),\n",
    "        tickfont=dict(color=\"#ab63fa\"),\n",
    "    )\n",
    "    fig.update_layout(title_text=\"Average DTN Latency over all Topics\")\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[*latencyOverTime.keys()],\n",
    "            y=[*latencyOverTime.values()],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"#ab63fa\", width=2),\n",
    "        ),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    # calc mean latency\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for val in latencyMap.values():\n",
    "        total += sum(val)\n",
    "        count += len(val)\n",
    "\n",
    "    print(f\"Mean Latency: {total/count}s\")\n",
    "\n",
    "def sumUntilKey(d, key):\n",
    "    total = 0\n",
    "    for i in range(0, key + 1):\n",
    "        total += d[i]\n",
    "    return total\n",
    "\n",
    "def dtnBundlesInFlight():\n",
    "    sentBundles = {\n",
    "        **dtndStats[\"base\"][\"sentBundles\"],\n",
    "        **dtndStats[\"robot\"][\"sentBundles\"],\n",
    "    }\n",
    "    receivedBundles = {\n",
    "        **dtndStats[\"base\"][\"receivedBundles\"],\n",
    "        **dtndStats[\"robot\"][\"receivedBundles\"],\n",
    "    }\n",
    "\n",
    "    bundlesMap = defaultdict(lambda: 0)\n",
    "    for time in sentBundles.values():\n",
    "        bundlesMap[int(time) + 1 - simStart] += 1\n",
    "    for time in receivedBundles.values():\n",
    "        bundlesMap[int(time) + 1 - simStart] -= 1\n",
    "\n",
    "    result = []\n",
    "    for time in range(0, simStop - simStart + 1):\n",
    "        result.append(sumUntilKey(bundlesMap, time))\n",
    "\n",
    "    # plot graph\n",
    "    fig = go.Figure()\n",
    "    fig.update_xaxes(title_text=\"Time [s]\", range=[0, simStop - simStart])\n",
    "    fig.update_layout(title_text=\"Number of bundles in flight\")\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=result,\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"#ab63fa\", width=2),\n",
    "        ),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def dtnBundleCount():\n",
    "    print(f\"\\nTransfered bundles over all nodes: {dtndStats['combined']['transferred']}\")\n",
    "\n",
    "\n",
    "dtnLatency()\n",
    "dtnBundlesInFlight()\n",
    "dtnBundleCount()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROS2DTN Proxy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End-To-End Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseE2eLatency():\n",
    "    sentMsgs = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    receivedMsgs = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        if not any(name in root for name in [\"robot\", \"base\"]):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if not re.search(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\\.log\", file):\n",
    "                continue\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.readlines()\n",
    "\n",
    "                for line in content:\n",
    "                    if not \";ROS;\" in line:\n",
    "                        continue\n",
    "                    timestamp, _, _, _, topic, _, _, msgHash = line.split(\";\")\n",
    "                    if \";ROS;TOPIC;PUB;\" in line:\n",
    "                        receivedMsgs[topic][msgHash.strip()] = datetime.fromisoformat(timestamp).timestamp()\n",
    "                    elif \"ROS;TOPIC;SUB;\" in line:\n",
    "                        sentMsgs[topic][msgHash.strip()] = datetime.fromisoformat(timestamp).timestamp()\n",
    "\n",
    "    \n",
    "    return (sentMsgs, receivedMsgs)\n",
    "\n",
    "def e2eLatency(data):\n",
    "\n",
    "    sentMsgs, receivedMsgs = data\n",
    "\n",
    "    for topic in sentMsgs.keys():\n",
    "        # Calculate latency\n",
    "        latencyMap = defaultdict(list)\n",
    "\n",
    "        # To plot over time, latency values of bundles received in one second are combined\n",
    "        for bid, time in receivedMsgs[topic].items():\n",
    "            sTime = sentMsgs[topic][bid]\n",
    "            latency = time - sTime\n",
    "            latencyMap[int(time) + 1].append(latency)\n",
    "        latencyOverTime = {}\n",
    "        for time, val in latencyMap.items():\n",
    "            latencyOverTime[time - simStart] = sum(val) / len(val)\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.update_xaxes(title_text=\"Time [s]\", range=[0, simStop - simStart])\n",
    "        fig.update_yaxes(\n",
    "            title_text=\"E2E Latency [s]\",\n",
    "            titlefont=dict(color=\"#ab63fa\"),\n",
    "            tickfont=dict(color=\"#ab63fa\"),\n",
    "        )\n",
    "        fig.update_layout(title_text=f\"Average End-To-End Latency for topic {topic}\")\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[*latencyOverTime.keys()],\n",
    "                y=[*latencyOverTime.values()],\n",
    "                mode=\"lines+markers\",\n",
    "                line=dict(color=\"#ab63fa\", width=2),\n",
    "            ),\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "        # calc mean & stddev\n",
    "        latencies = []\n",
    "        for val in latencyMap.values():\n",
    "            latencies.extend(val)\n",
    "\n",
    "        print(f\"Mean Latency: {statistics.mean(latencies)}s\")\n",
    "        print(f\"StDev: {statistics.stdev(latencies)}s\")\n",
    "\n",
    "e2eLatency(parseE2eLatency())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latencyInputPipeline():\n",
    "    result = {}\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        if not any(name in root for name in [\"robot\"]):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if not re.search(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\\.log\", file):\n",
    "                continue\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.readlines()\n",
    "            \n",
    "            for index, line in enumerate(content):\n",
    "                if \"DTN;TOPIC\" in line:\n",
    "                    end, _, _, _, endTopic, _, _ = line.split(\";\")\n",
    "                    end = end.split(\"+\")[0]\n",
    "                    start, _, _, _, startTopic, _, _, _ = content[index - 1].split(\";\")\n",
    "                    start = start.split(\"+\")[0]\n",
    "                    if endTopic == startTopic:\n",
    "                        result.setdefault(endTopic, [])\n",
    "                        diff = datetime.fromisoformat(end).timestamp() - datetime.fromisoformat(start).timestamp()\n",
    "                        result[endTopic].append(diff)\n",
    "                    else:\n",
    "                        raise ValueError(\"Topics should be the same!\")\n",
    "                elif \"ROS;TOPIC\" in line:\n",
    "                    topic = line.split(\";\")[4]\n",
    "                    count[topic] += 1\n",
    "    \n",
    "    print(\"Input Pipline Latency\")\n",
    "    for topic, values in result.items():\n",
    "        print(f\"{topic}:\\tSamples: {count[topic]}\\tMean: {statistics.mean(values)}\\t StDev: {statistics.stdev(values)}\")\n",
    "\n",
    "def latencyOutputPipeline():\n",
    "    result = {}\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        if not any(name in root for name in [\"base\"]):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if not re.search(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\\.log\", file):\n",
    "                continue\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.readlines()\n",
    "            \n",
    "            for index, line in enumerate(content):\n",
    "                if \"DTN;TOPIC\" in line:\n",
    "                    start, _, _, _, startTopic, _, _ = line.split(\";\")\n",
    "                    start = start.split(\"+\")[0]\n",
    "                    end, _, _, _, endTopic, _, _, _ = content[index + 1].split(\";\")\n",
    "                    end = end.split(\"+\")[0]\n",
    "                    if endTopic == startTopic:\n",
    "                        result.setdefault(endTopic, [])\n",
    "                        diff = datetime.fromisoformat(end).timestamp() - datetime.fromisoformat(start).timestamp()\n",
    "                        result[endTopic].append(diff)\n",
    "                        count[endTopic] += 1\n",
    "                    else:\n",
    "                        raise ValueError(\"Topics should be the same!\")\n",
    "    \n",
    "    print(\"\\nOutput Pipline Latency\")\n",
    "    for topic, values in result.items():\n",
    "        print(f\"{topic}:\\tSamples: {count[topic]}\\tMean: {statistics.mean(values)}\\t StDev: {statistics.stdev(values)}\")\n",
    "\n",
    "latencyInputPipeline()\n",
    "latencyOutputPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseProxyStats():\n",
    "    # TODO: replace dtn values on sender with ros values on receiver\n",
    "    topics = set()\n",
    "    sizeDtn = {}\n",
    "    sizeRos = {}\n",
    "    cntDtn = {}\n",
    "    cntRos = {}\n",
    "\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        if not any(name in root for name in [\"base\", \"robot\"]):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if not re.search(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\\.log\", file):\n",
    "                continue\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.readlines()\n",
    "\n",
    "            for line in content:\n",
    "                # only use subscriptions to prevent duplication\n",
    "                if not \";TOPIC;SUB;\" in line:\n",
    "                    continue\n",
    "                timestamp, tech, _, _, topic, type, size, *_ = line.split(\";\")\n",
    "                # timestamp = datetime.fromisoformat(timestamp).timestamp()\n",
    "                topics.add(topic)\n",
    "                sizeDtn.setdefault(topic, [])\n",
    "                sizeRos.setdefault(topic, [])\n",
    "                cntDtn.setdefault(topic, 0)\n",
    "                cntRos.setdefault(topic, 0)\n",
    "\n",
    "                if \"DTN\" == tech:\n",
    "                    sizeDtn[topic].append(int(size))\n",
    "                    cntDtn[topic] += 1\n",
    "                elif \"ROS\" == tech:\n",
    "                    sizeRos[topic].append(int(size))\n",
    "                    cntRos[topic] += 1\n",
    "\n",
    "    for topic, values in sizeDtn.items():\n",
    "        total = sum(values)\n",
    "        sizeDtn[topic] = total / len(values)\n",
    "\n",
    "    for topic, values in sizeRos.items():\n",
    "        total = sum(values)\n",
    "        sizeRos[topic] = total / len(values)\n",
    "    \n",
    "    sizeDtn = sorted(sizeDtn.items(), key=lambda x: x[0])\n",
    "    sizeRos = sorted(sizeRos.items(), key=lambda x: x[0])\n",
    "    cntDtn = sorted(cntDtn.items(), key=lambda x: x[0])\n",
    "    cntRos = sorted(cntRos.items(), key=lambda x: x[0])\n",
    "\n",
    "    topics = [item[0] for item in sizeDtn]\n",
    "    sizeDtn = [item[1] for item in sizeDtn]\n",
    "    sizeRos = [item[1] for item in sizeRos]\n",
    "    cntDtn = [item[1] for item in cntDtn]\n",
    "    cntRos = [item[1] for item in cntRos]\n",
    "\n",
    "    return (topics, cntRos, cntDtn, sizeRos, sizeDtn)\n",
    "\n",
    "\n",
    "def dtnProxyStats(parsedData):\n",
    "    topics, cntRos, cntDtn, sizeRos, sizeDtn = parsedData\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2, subplot_titles=(\"Message Count\", \"Message Size\")\n",
    "    )\n",
    "\n",
    "    fig.update_layout(barmode=\"group\", title_text=\"Bidirectional Message Statistics\")\n",
    "    fig.update_yaxes(title_text=\"Message Size [B]\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Message Count\", row=1, col=1)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"ROS\",\n",
    "            x=topics,\n",
    "            y=cntRos,\n",
    "            texttemplate=\"%{y:.r}\",\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=\"#ab63fa\"),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"DTN\",\n",
    "            x=topics,\n",
    "            y=cntDtn,\n",
    "            texttemplate=\"%{y:.r}\",\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=\"#00cc96\"),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"ROS\",\n",
    "            x=topics,\n",
    "            y=sizeRos,\n",
    "            texttemplate=\"%{y:.1f}\",\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=\"#ab63fa\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"DTN\",\n",
    "            x=topics,\n",
    "            y=sizeDtn,\n",
    "            texttemplate=\"%{y:.1f}\",\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=\"#00cc96\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    # print stats per topic\n",
    "    # bandwidth\n",
    "    print(\"Transferred Bandwith (DTN payload ONLY)\")\n",
    "    for topic, cnt, size in zip(topics, cntDtn, sizeDtn):\n",
    "        print(f\"{topic + ':':<20} \\t{(cnt * size) / 1000} kB\")\n",
    "\n",
    "    # count\n",
    "    print(\"\\nMessage Count reduction (ROS -> DTN)\")\n",
    "    for topic, ros, dtn in zip(topics, cntRos, cntDtn):\n",
    "        print(f\"{topic + ':':<20} \\t{ros - dtn} = {((ros-dtn)/ros*100):.2f}%\")\n",
    "\n",
    "    # size\n",
    "    print(\"\\nMessage Size reduction (ROS -> DTN)\")\n",
    "    for topic, ros, dtn in zip(topics, sizeRos, sizeDtn):\n",
    "        print(f\"{topic + ':':<25}{f'{(ros - dtn):.2f}':<10} Bytes = {((ros-dtn)/ros*100):05.2f}%\")\n",
    "\n",
    "parsedData = parseProxyStats()\n",
    "dtnProxyStats(parsedData)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
