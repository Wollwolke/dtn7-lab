{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# PATH = \"../../dtn7-lab/shared/scenarios/correctness/expire/results-correctness_expire-1684232160/\"\n",
    "\n",
    "# Load path\n",
    "with open('.nbconfig', 'r') as file:\n",
    "    arguments = json.load(file)\n",
    "    PATH = arguments[\"path\"]\n",
    "\n",
    "print(f\"Report for {PATH}\")\n",
    "\n",
    "\n",
    "with open(PATH + \"start.txt\") as file:\n",
    "    simStart = int(file.readline().strip())\n",
    "with open(PATH + \"stop.txt\") as file:\n",
    "    simStop = int(file.readline().strip())\n",
    "\n",
    "stats = {}\n",
    "stats[\"duration\"] = simStop - simStart\n",
    "\n",
    "def mean(data):\n",
    "    n = 0\n",
    "    mean = 0.0\n",
    " \n",
    "    for x in data:\n",
    "        n += 1\n",
    "        mean += (x - mean)/n\n",
    "\n",
    "    if n < 1:\n",
    "        return float('nan')\n",
    "    else:\n",
    "        return mean\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotResourceGraphs():\n",
    "    logfiles = []\n",
    "\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        for file in files:\n",
    "            if file in [\"pidstat-base.csv.log\", \"pidstat-robot.csv.log\"]:\n",
    "                logfiles.append(root + \"/\" + file)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        subplot_titles=(\"Base\", \"Robot\"),\n",
    "        specs=[[{\"secondary_y\": True}, {\"secondary_y\": True}]],\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Time [s]\")\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"RSS [kB]\",\n",
    "        secondary_y=False,\n",
    "        titlefont=dict(color=\"#ab63fa\"),\n",
    "        tickfont=dict(color=\"#ab63fa\"),\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"CPU Usage [%]\",\n",
    "        secondary_y=True,\n",
    "        titlefont=dict(color=\"#00cc96\"),\n",
    "        tickfont=dict(color=\"#00cc96\"),\n",
    "    )\n",
    "    fig.update_layout(title_text=\"Resource Usage\", showlegend=False)\n",
    "\n",
    "    for file in logfiles:\n",
    "        # Get node name\n",
    "        nodeName = re.search(r\"/pidstat-(\\w*)\", file).group(1)\n",
    "        column = 1 if (\"base\" in nodeName) else 2\n",
    "\n",
    "        # Get number of CPU Cores\n",
    "        with open(file.replace(\".csv\", \"\")) as f:\n",
    "            cpuCores = int(re.search(r\"\\((\\d*) CPU\\)\", f.readline()).group(1))\n",
    "\n",
    "        df = pd.read_csv(file, sep=\"\\s+\", usecols=[0, 7, 11, 12])\n",
    "        # substract start time\n",
    "        df = df.subtract([simStart, 0, 0, 0], axis=\"columns\")\n",
    "        # devide CPU usage by core count\n",
    "        df = df.divide([1, cpuCores, 1, 1], axis=\"columns\")\n",
    "\n",
    "        # plot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df[\"Time\"],\n",
    "                y=df[\"RSS\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"RSS\",\n",
    "                line=dict(color=\"#ab63fa\", width=2),\n",
    "            ),\n",
    "            secondary_y=False,\n",
    "            row=1,\n",
    "            col=column,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df[\"Time\"],\n",
    "                y=df[\"%CPU\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"CPU\",\n",
    "                line=dict(color=\"#00cc96\", width=2),\n",
    "            ),\n",
    "            secondary_y=True,\n",
    "            row=1,\n",
    "            col=column,\n",
    "        )\n",
    "\n",
    "        # Print mean values\n",
    "        stats = f\"Mean Values {nodeName}:\\nCPU: \\t{df.loc[:,'%CPU'].mean()} %\\nRSS: \\t{df.loc[:,'RSS'].mean()} kB\\n\"\n",
    "        print(stats)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plotResourceGraphs()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNetworkGraphs():\n",
    "    global stats\n",
    "    logfiles = {}\n",
    "\n",
    "    # find log files\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        for file in files:\n",
    "            m = re.match(r\"net-(.+).log\", file)\n",
    "            if m:\n",
    "                logfiles[m.group(1)] = root + \"/\" + file\n",
    "\n",
    "    # load data\n",
    "    dfs = []\n",
    "    for nodeName, file in logfiles.items():\n",
    "        df = pd.read_csv(\n",
    "            file,\n",
    "            sep=\";\",\n",
    "            usecols=[0, 1, 2, 3, 4],\n",
    "            names=\"timestamp;iface_name;bytes_out/s;bytes_in/s;bytes_total/s\".split(\n",
    "                \";\"\n",
    "            ),\n",
    "        )\n",
    "        df[\"node\"] = nodeName\n",
    "\n",
    "        # filter\n",
    "        df = df[df[\"iface_name\"] == \"eth0\"]\n",
    "        df = df[df[\"timestamp\"] > simStart]\n",
    "\n",
    "        # substract start time\n",
    "        df[\"timestamp\"] -= simStart\n",
    "        df[\"timestamp\"] = df[\"timestamp\"].astype(\"int\")\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.sort_values(by=[\"timestamp\", \"node\"])\n",
    "\n",
    "    # init figure\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        subplot_titles=(\"Traffic In\", \"Traffic Out\", \"Total Traffic\"),\n",
    "        vertical_spacing=0.1,\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Time [s]\")\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Traffic [B/s]\",\n",
    "    )\n",
    "    fig.update_layout(title_text=\"Network Usage\", height=900)\n",
    "\n",
    "    # plot data\n",
    "    colors = [\"#ab63fa\", \"#00cc96\", \"#ffa15a\", \"blue\"]\n",
    "    colorCnt = 0\n",
    "    for nodeName in df.node.unique():\n",
    "        nodeDf = df[df.node == nodeName]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=nodeDf[\"timestamp\"],\n",
    "                y=nodeDf[\"bytes_in/s\"],\n",
    "                mode=\"lines\",\n",
    "                name=nodeName,\n",
    "                line=dict(color=colors[colorCnt]),\n",
    "                legendgroup=colorCnt,\n",
    "                showlegend=True,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=nodeDf[\"timestamp\"],\n",
    "                y=nodeDf[\"bytes_out/s\"],\n",
    "                mode=\"lines\",\n",
    "                name=nodeName,\n",
    "                line=dict(color=colors[colorCnt]),\n",
    "                legendgroup=colorCnt,\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=nodeDf[\"timestamp\"],\n",
    "                y=nodeDf[\"bytes_total/s\"],\n",
    "                mode=\"lines\",\n",
    "                name=nodeName,\n",
    "                line=dict(color=colors[colorCnt]),\n",
    "                legendgroup=colorCnt,\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=3,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        colorCnt += 1\n",
    "\n",
    "    # plot means\n",
    "    meanIn = df[\"bytes_in/s\"].describe().T[\"mean\"]\n",
    "    meanOut = df[\"bytes_out/s\"].describe().T[\"mean\"]\n",
    "    meanTotal = df[\"bytes_total/s\"].describe().T[\"mean\"]\n",
    "\n",
    "    fig.add_hline(\n",
    "        meanIn,\n",
    "        line=dict(color=\"red\", dash=\"dash\", width=1),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_hline(\n",
    "        meanOut,\n",
    "        line=dict(color=\"red\", dash=\"dash\", width=1),\n",
    "        row=2,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_hline(\n",
    "        meanTotal,\n",
    "        line=dict(color=\"red\", dash=\"dash\", width=1),\n",
    "        row=3,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    print(\"(Combined Nodes) Mean Network usage:\")\n",
    "    print(\n",
    "        f\"In: \\t{meanIn:.2f} B/s\\nOut: \\t{meanOut:.2f} B/s\\nTotal: \\t{meanTotal:.2f} B/s\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nTotal Traffic:\")\n",
    "    for nodeName in df.node.unique():\n",
    "        nodeDf = df[df.node == nodeName]\n",
    "        print(\n",
    "            f\"{nodeName} \\tIn: {str(sum(nodeDf['bytes_in/s'])/1000) + ' kB':<15} Out: {sum(nodeDf['bytes_out/s'])/1000} kB\"\n",
    "        )\n",
    "\n",
    "    stats[\"totalTraffic\"] = df[\"bytes_total/s\"].sum()\n",
    "\n",
    "plotNetworkGraphs()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing dtnd stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtndStats = {\"base\": {}, \"robot\": {}, \"combined\": {}}\n",
    "\n",
    "\n",
    "def loadDtndStats():\n",
    "    global dtnStats\n",
    "\n",
    "    # init\n",
    "    for node in dtndStats:\n",
    "        dtndStats[node][\"sentBundles\"] = {}\n",
    "        dtndStats[node][\"receivedBundles\"] = {}\n",
    "        dtndStats[node][\"superseded\"] = {}\n",
    "\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        for file in files:\n",
    "            if file != \"dtnd.log\":\n",
    "                continue\n",
    "            nodeName = re.search(r\"\\/(\\w*)$\", root).group(1)\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.read()\n",
    "\n",
    "            if nodeName in [\"base\", \"robot\"]:\n",
    "\n",
    "                dtndStats[nodeName][\"created\"] = len(re.findall(r\"Transmission of bundle requested\", content))\n",
    "                dtndStats[nodeName][\"transferred\"] = len(re.findall(r\"Sending bundle succeeded\", content))\n",
    "                dtndStats[nodeName][\"relayed\"] = len(re.findall(r\"Received new bundle\", content))\n",
    "                dtndStats[nodeName][\"aborted\"] = len(re.findall(r\"Sending bundle .+ failed\", content))\n",
    "                dtndStats[nodeName][\"dropped\"] = len(re.findall(r\"Dropping bundle\", content))\n",
    "                dtndStats[nodeName][\"removed\"] = len(re.findall(r\"Removing bundle\", content)) - dtndStats[nodeName][\"dropped\"]\n",
    "                dtndStats[nodeName][\"refused\"] = len(re.findall(r\"refusing bundle\", content))\n",
    "                dtndStats[nodeName][\"delivered\"] = len(re.findall(r\"Received bundle for local delivery\", content))\n",
    "\n",
    "                tmp = re.findall(r\"(\\d{4}-\\d{2}-\\d{2}T.+Z).*Received bundle for local delivery.+\\/\\/(.+)\", content)\n",
    "                for time, bid in tmp:\n",
    "                    dtndStats[nodeName][\"receivedBundles\"][bid] = datetime.fromisoformat(time).timestamp()\n",
    "                tmp = re.findall(r\"(\\d{4}-\\d{2}-\\d{2}T.+Z).*Transmission of bundle requested.+\\/\\/(.+)\", content)\n",
    "                for time, bid in tmp:\n",
    "                    dtndStats[nodeName][\"sentBundles\"][bid] = datetime.fromisoformat(time).timestamp()\n",
    "                tmp = re.findall(r\"(\\d{4}-\\d{2}-\\d{2}T.+Z).*Bundle.+\\/\\/(.+) is superseded by\", content)\n",
    "                for time, bid in tmp:\n",
    "                    dtndStats[nodeName][\"superseded\"][bid] = datetime.fromisoformat(time).timestamp()\n",
    "\n",
    "            try:\n",
    "                dtndStats[\"combined\"][\"transferred\"] += len(re.findall(r\"Sending bundle succeeded\", content))\n",
    "            except (KeyError):\n",
    "                dtndStats[\"combined\"][\"transferred\"] = len(re.findall(r\"Sending bundle succeeded\", content))\n",
    "\n",
    "loadDtndStats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTN Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtnLatency():\n",
    "    global dtndStats\n",
    "\n",
    "    sentBundles = {\n",
    "        **dtndStats[\"base\"][\"sentBundles\"],\n",
    "        **dtndStats[\"robot\"][\"sentBundles\"],\n",
    "    }\n",
    "    receivedBundles = {\n",
    "        **dtndStats[\"base\"][\"receivedBundles\"],\n",
    "        **dtndStats[\"robot\"][\"receivedBundles\"],\n",
    "    }\n",
    "\n",
    "    # Calculate latency\n",
    "    latencyMap = defaultdict(list)\n",
    "\n",
    "    # To plot over time, latency values of bundles received in one second are combined\n",
    "    for bid, time in receivedBundles.items():\n",
    "        sTime = sentBundles[bid]\n",
    "        latency = time - sTime\n",
    "        latencyMap[int(time) + 1].append(latency)\n",
    "    latencyOverTime = {}\n",
    "    for time, val in latencyMap.items():\n",
    "        latencyOverTime[time - simStart] = sum(val) / len(val)\n",
    "\n",
    "    stats[\"dtnLatency\"] = latencyOverTime\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.update_xaxes(title_text=\"Time [s]\", range=[0, simStop - simStart])\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"DTN Latency [s]\",\n",
    "        titlefont=dict(color=\"#ab63fa\"),\n",
    "        tickfont=dict(color=\"#ab63fa\"),\n",
    "    )\n",
    "    fig.update_layout(title_text=\"Average DTN Latency over all Topics\")\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[*latencyOverTime.keys()],\n",
    "            y=[*latencyOverTime.values()],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"#ab63fa\", width=2),\n",
    "        ),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    # calc mean latency\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for val in latencyMap.values():\n",
    "        total += sum(val)\n",
    "        count += len(val)\n",
    "\n",
    "    print(f\"Mean Latency: {total/count}s\")\n",
    "\n",
    "\n",
    "def transmissionProbability():\n",
    "    global dtndStats, stats\n",
    "\n",
    "    sentBundles = {\n",
    "        **dtndStats[\"base\"][\"sentBundles\"],\n",
    "        **dtndStats[\"robot\"][\"sentBundles\"],\n",
    "    }\n",
    "    receivedBundles = {\n",
    "        **dtndStats[\"base\"][\"receivedBundles\"],\n",
    "        **dtndStats[\"robot\"][\"receivedBundles\"],\n",
    "    }\n",
    "    supersededBundles = {\n",
    "        # **dtndStats[\"base\"][\"superseded\"],\n",
    "        **dtndStats[\"robot\"][\"superseded\"],\n",
    "    }\n",
    "\n",
    "    # remove superseded bundles, that are already delivered\n",
    "    idsToRemove = []\n",
    "    for bundleId in supersededBundles.keys():\n",
    "        if bundleId in receivedBundles.keys():\n",
    "            idsToRemove.append(bundleId)\n",
    "    for id in idsToRemove:\n",
    "        del supersededBundles[id]\n",
    "\n",
    "    # Calculate Propability\n",
    "    sentMap = {}\n",
    "    receivedMap = {}\n",
    "\n",
    "    for timeStep in range(0, simStop - simStart + 1):\n",
    "        sentMap[timeStep] = sum(\n",
    "            1 for value in sentBundles.values() if value - simStart <= timeStep\n",
    "        )\n",
    "        sentMap[timeStep] -= sum(\n",
    "            1 for value in supersededBundles.values() if value - simStart <= timeStep\n",
    "        )\n",
    "        receivedMap[timeStep] = sum(\n",
    "            1 for value in receivedBundles.values() if value - simStart <= timeStep\n",
    "        )\n",
    "\n",
    "    probaOverTime = {}\n",
    "    for timeStep, value in sentMap.items():\n",
    "        if value == 0:\n",
    "            probaOverTime[timeStep] = None\n",
    "        else:\n",
    "            probaOverTime[timeStep] = receivedMap[timeStep] / value\n",
    "\n",
    "    stats[\"delivery\"] = probaOverTime\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.update_xaxes(title_text=\"Time [s]\", range=[0, simStop - simStart])\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Delivery Probability\",\n",
    "        titlefont=dict(color=\"#ab63fa\"),\n",
    "        tickfont=dict(color=\"#ab63fa\"),\n",
    "        range=[0, 1.1],\n",
    "    )\n",
    "    fig.update_layout(title_text=\"Delivery Probability over all Topics\")\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[*probaOverTime.keys()],\n",
    "            y=[*probaOverTime.values()],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"#ab63fa\", width=2),\n",
    "        ),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def sumUntilKey(d, key):\n",
    "    total = 0\n",
    "    for i in range(0, key + 1):\n",
    "        total += d[i]\n",
    "    return total\n",
    "\n",
    "\n",
    "def dtnBundlesInFlight():\n",
    "    global stats\n",
    "\n",
    "    sentBundles = {\n",
    "        **dtndStats[\"base\"][\"sentBundles\"],\n",
    "        **dtndStats[\"robot\"][\"sentBundles\"],\n",
    "    }\n",
    "    receivedBundles = {\n",
    "        **dtndStats[\"base\"][\"receivedBundles\"],\n",
    "        **dtndStats[\"robot\"][\"receivedBundles\"],\n",
    "    }\n",
    "    supersededBundles = {\n",
    "        # **dtndStats[\"base\"][\"superseded\"],\n",
    "        **dtndStats[\"robot\"][\"superseded\"],\n",
    "    }\n",
    "\n",
    "    bundlesMap = defaultdict(lambda: 0)\n",
    "    for time in sentBundles.values():\n",
    "        bundlesMap[int(time) + 1 - simStart] += 1\n",
    "    for time in receivedBundles.values():\n",
    "        bundlesMap[int(time) + 1 - simStart] -= 1\n",
    "    for bundleId, time in supersededBundles.items():\n",
    "        if bundleId not in receivedBundles.keys():\n",
    "            bundlesMap[int(time) + 1 - simStart] -= 1\n",
    "\n",
    "    result = []\n",
    "    for time in range(0, simStop - simStart + 1):\n",
    "        result.append(sumUntilKey(bundlesMap, time))\n",
    "\n",
    "    stats[\"bundlesInFlight\"] = result\n",
    "\n",
    "    # plot graph\n",
    "    fig = go.Figure()\n",
    "    fig.update_xaxes(title_text=\"Time [s]\", range=[0, simStop - simStart])\n",
    "    fig.update_layout(title_text=\"Number of bundles in flight\")\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=result,\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"#ab63fa\", width=2),\n",
    "        ),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def dtnBundleCount():\n",
    "    global stats\n",
    "    stats[\"bundleCount\"] = dtndStats[\"combined\"][\"transferred\"]\n",
    "    print(\n",
    "        f\"\\nTransfered bundles over all nodes: {dtndStats['combined']['transferred']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "dtnLatency()\n",
    "dtnBundlesInFlight()\n",
    "dtnBundleCount()\n",
    "transmissionProbability()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROS2DTN Proxy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End-To-End Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseE2eLatency():\n",
    "    sentMsgs = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    receivedMsgs = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        if not any(name in root for name in [\"robot\", \"base\"]):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if not re.search(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\\.log\", file):\n",
    "                continue\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.readlines()\n",
    "\n",
    "                for line in content:\n",
    "                    if not \";ROS;\" in line:\n",
    "                        continue\n",
    "                    timestamp, _, _, _, topic, _, _, msgHash = line.split(\";\")\n",
    "                    if \";ROS;TOPIC;PUB;\" in line:\n",
    "                        receivedMsgs[topic][msgHash.strip()] = datetime.fromisoformat(timestamp).timestamp()\n",
    "                    elif \"ROS;TOPIC;SUB;\" in line:\n",
    "                        hostname = root.split(\"/\")[-1]\n",
    "                        sentMsgs[f\"/{hostname}{topic}\"][msgHash.strip()] = datetime.fromisoformat(timestamp).timestamp()\n",
    "\n",
    "    \n",
    "    return (sentMsgs, receivedMsgs)\n",
    "\n",
    "def e2eLatency(data):\n",
    "    global stats\n",
    "    stats[\"e2e\"] = defaultdict(list)\n",
    "\n",
    "    sentMsgs, receivedMsgs = data\n",
    "\n",
    "    for topic in sentMsgs.keys():\n",
    "        # Calculate latency\n",
    "        latencyMap = defaultdict(list)\n",
    "\n",
    "        # To plot over time, latency values of bundles received in one second are combined\n",
    "        for bid, time in receivedMsgs[topic].items():\n",
    "            sTime = sentMsgs[topic][bid]\n",
    "            latency = time - sTime\n",
    "            latencyMap[int(time) + 1].append(latency)\n",
    "        latencyOverTime = {}\n",
    "        for time, val in latencyMap.items():\n",
    "            latencyOverTime[time - simStart] = sum(val) / len(val)\n",
    "            stats[\"e2e\"][topic].extend(val)\n",
    "\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.update_xaxes(title_text=\"Time [s]\", range=[0, simStop - simStart])\n",
    "        fig.update_yaxes(\n",
    "            title_text=\"E2E Latency [s]\",\n",
    "            titlefont=dict(color=\"#ab63fa\"),\n",
    "            tickfont=dict(color=\"#ab63fa\"),\n",
    "        )\n",
    "        fig.update_layout(title_text=f\"Average End-To-End Latency for topic {topic}\")\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[*latencyOverTime.keys()],\n",
    "                y=[*latencyOverTime.values()],\n",
    "                mode=\"lines+markers\",\n",
    "                line=dict(color=\"#ab63fa\", width=2),\n",
    "            ),\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "        # calc mean & stddev\n",
    "        latencies = []\n",
    "        for val in latencyMap.values():\n",
    "            latencies.extend(val)\n",
    "\n",
    "        print(f\"Mean Latency: {statistics.mean(latencies)}s\")\n",
    "        print(f\"StDev: {statistics.stdev(latencies)}s\")\n",
    "\n",
    "e2eLatency(parseE2eLatency())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latencyInputPipeline():\n",
    "    result = defaultdict(list)\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        if not any(name in root for name in [\"robot\", \"base\"]):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if not re.search(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\\.log\", file):\n",
    "                continue\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.readlines()\n",
    "            \n",
    "            for index, line in enumerate(content):\n",
    "                if \"DTN;TOPIC;SUB\" in line:\n",
    "                    end, _, _, _, endTopic, _, _ = line.split(\";\")\n",
    "                    end = end.split(\"+\")[0]\n",
    "                    start, _, _, _, startTopic, _, _, _ = content[index - 1].split(\";\")\n",
    "                    start = start.split(\"+\")[0]\n",
    "                    if endTopic == startTopic:\n",
    "                        diff = datetime.fromisoformat(end).timestamp() - datetime.fromisoformat(start).timestamp()\n",
    "                        result[endTopic].append(diff)\n",
    "                    else:\n",
    "                        raise ValueError(\"Topics should be the same!\")\n",
    "                elif \"ROS;TOPIC;SUB\" in line:\n",
    "                    topic = line.split(\";\")[4]\n",
    "                    count[topic] += 1\n",
    "    \n",
    "    print(\"Input Pipline Latency\")\n",
    "    for topic, values in result.items():\n",
    "        print(f\"{topic}:\\tSamples: {count[topic]}\\tMean: {statistics.mean(values)}\\t StDev: {statistics.stdev(values)}\")\n",
    "\n",
    "def latencyOutputPipeline():\n",
    "    result = defaultdict(list)\n",
    "    count = defaultdict(lambda: 0)\n",
    "    warningPrinted = False\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        if not any(name in root for name in [\"robot\", \"base\"]):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if not re.search(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\\.log\", file):\n",
    "                continue\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.readlines()\n",
    "            \n",
    "            for index, line in enumerate(content):\n",
    "                # this might break when dtn_proxy is executed multithreaded\n",
    "                if \"DTN;TOPIC;PUB\" in line:\n",
    "                    start, _, _, _, startTopic, _, _ = line.split(\";\")\n",
    "                    start = start.split(\"+\")[0]\n",
    "                    end, _, _, _, endTopic, _, _, _ = content[index + 1].split(\";\")\n",
    "                    endTopic = \"/\" + endTopic.split(\"/\")[-1]\n",
    "                    end = end.split(\"+\")[0]\n",
    "                    diff = datetime.fromisoformat(end).timestamp() - datetime.fromisoformat(start).timestamp()\n",
    "                    result[startTopic].append(diff)\n",
    "                    count[startTopic] += 1\n",
    "                    if endTopic != startTopic and not warningPrinted:\n",
    "                        print(\"\\n⚠ Topics should be the same. Did you use the combine/split module?\")\n",
    "                        warningPrinted = True\n",
    "    \n",
    "    print(\"\\nOutput Pipline Latency\")\n",
    "    for topic, values in result.items():\n",
    "        print(f\"{topic}:\\tSamples: {count[topic]}\\tMean: {statistics.mean(values)}\\t StDev: {statistics.stdev(values)}\")\n",
    "\n",
    "latencyInputPipeline()\n",
    "latencyOutputPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseProxyStats():\n",
    "    sizeDtn = defaultdict(list)\n",
    "    sizeRos = defaultdict(list)\n",
    "    sizeRosReceived = defaultdict(list)\n",
    "    cntDtn = defaultdict(lambda: 0)\n",
    "    cntRos = defaultdict(lambda: 0)\n",
    "\n",
    "    for root, _, files in os.walk(PATH):\n",
    "        if not any(name in root for name in [\"base\", \"robot\"]):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if not re.search(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\\.log\", file):\n",
    "                continue\n",
    "            with open(root + \"/\" + file) as f:\n",
    "                content = f.readlines()\n",
    "\n",
    "            for line in content:\n",
    "                # only use subscriptions to prevent duplication\n",
    "                if \";TOPIC;SUB;\" in line:\n",
    "                    _, tech, _, _, topic, type, size, *_ = line.split(\";\")\n",
    "                    hostname = root.split(\"/\")[-1]\n",
    "                    topic = \"/\" + hostname + topic\n",
    "\n",
    "                    if \"DTN\" == tech:\n",
    "                        sizeDtn[topic].append(int(size))\n",
    "                        cntDtn[topic] += 1\n",
    "                    elif \"ROS\" == tech:\n",
    "                        sizeRos[topic].append(int(size))\n",
    "                        cntRos[topic] += 1\n",
    "\n",
    "                elif \";ROS;TOPIC;PUB;\" in line:\n",
    "                    _, _, _, _, topic, _, size, *_ = line.split(\";\")\n",
    "                    sizeRosReceived[topic].append(int(size))\n",
    "\n",
    "    for topic in cntRos.keys():\n",
    "        sizeDtn[topic] = mean(sizeDtn[topic])\n",
    "        sizeRos[topic] = mean(sizeRos[topic])\n",
    "        sizeRosReceived[topic] = mean(sizeRosReceived[topic])\n",
    "\n",
    "    sizeDtn = sorted(sizeDtn.items(), key=lambda x: x[0])\n",
    "    sizeRos = sorted(sizeRos.items(), key=lambda x: x[0])\n",
    "    sizeRosReceived = sorted(sizeRosReceived.items(), key=lambda x: x[0])\n",
    "    cntDtn = sorted(cntDtn.items(), key=lambda x: x[0])\n",
    "    cntRos = sorted(cntRos.items(), key=lambda x: x[0])\n",
    "\n",
    "    topics = [item[0] for item in cntRos]\n",
    "    sizeDtn = [item[1] for item in sizeDtn]\n",
    "    sizeRos = [item[1] for item in sizeRos]\n",
    "    sizeRosReceived = [item[1] for item in sizeRosReceived]\n",
    "    cntDtn = [item[1] for item in cntDtn]\n",
    "    cntRos = [item[1] for item in cntRos]\n",
    "\n",
    "    return (topics, cntRos, cntDtn, sizeRos, sizeDtn, sizeRosReceived)\n",
    "\n",
    "\n",
    "def dtnProxyStats(parsedData):\n",
    "    global stats\n",
    "    stats[\"size\"] = {}\n",
    "\n",
    "    topics, cntRos, cntDtn, sizeRos, sizeDtn, sizeRosReceived = parsedData\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2, subplot_titles=(\"Message Count\", \"Message Size\")\n",
    "    )\n",
    "\n",
    "    fig.update_layout(barmode=\"group\", title_text=\"Bidirectional Message Statistics\")\n",
    "    fig.update_yaxes(title_text=\"Message Size [B]\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Message Count\", row=1, col=1)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"ROS\",\n",
    "            x=topics,\n",
    "            y=cntRos,\n",
    "            texttemplate=\"%{y:.r}\",\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=\"#ab63fa\"),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"DTN\",\n",
    "            x=topics,\n",
    "            y=cntDtn,\n",
    "            texttemplate=\"%{y:.r}\",\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=\"#00cc96\"),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"ROS\",\n",
    "            x=topics,\n",
    "            y=sizeRos,\n",
    "            texttemplate=\"%{y:.1f}\",\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=\"#ab63fa\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"DTN\",\n",
    "            x=topics,\n",
    "            y=sizeDtn,\n",
    "            texttemplate=\"%{y:.1f}\",\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=\"#00cc96\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"ROS Out\",\n",
    "            x=topics,\n",
    "            y=sizeRosReceived,\n",
    "            texttemplate=\"%{y:.1f}\",\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=\"#ffa15a\"),\n",
    "            showlegend=True,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    # print stats per topic\n",
    "    # bandwidth\n",
    "    print(\"Transferred Bandwith (incoming DTN payload ONLY)\")\n",
    "    for topic, cnt, size in zip(topics, cntDtn, sizeDtn):\n",
    "        print(f\"{topic + ':':<20} \\t{(cnt * size) / 1000} kB\")\n",
    "\n",
    "    # count\n",
    "    print(\"\\nMessage Count reduction (ROS -> DTN)\")\n",
    "    for topic, ros, dtn in zip(topics, cntRos, cntDtn):\n",
    "        print(f\"{topic + ':':<20} \\t{ros - dtn} = {((ros-dtn)/ros*100):.2f}%\")\n",
    "\n",
    "    # size\n",
    "    print(\"\\nMessage Size reduction (ROS -> DTN)\")\n",
    "    for topic, ros, dtn in zip(topics, sizeRos, sizeDtn):\n",
    "        print(f\"{topic + ':':<25}{f'{(ros - dtn):.2f}':<10} Bytes = {((ros-dtn)/ros*100):05.2f}%\")\n",
    "        stats[\"size\"][topic] = dtn\n",
    "\n",
    "parsedData = parseProxyStats()\n",
    "dtnProxyStats(parsedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save stats to file\n",
    "with open(f\"{PATH}/stats.json\", \"w\") as file:\n",
    "    json.dump(stats, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
